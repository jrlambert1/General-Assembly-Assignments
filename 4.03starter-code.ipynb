{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1: Suppose you administer a questionnaire that involves the following question:\n",
    "\n",
    "- \"Do you think things are heading in the right direction or do you believe things have pretty seriously gotten off on the wrong track?\"\n",
    "\n",
    "You want to take these 1,000 survey responses as your $Y$ and build a model using geographic and demographic data to predict answers for the rest of your voting population. What generalized linear model is most appropriate here? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is going to be a binary response variable i.e. yes/no. You are therefore going to want to use a logistical\n",
    "#regression model to look at the probability of a 'yes' reponse limited to between 0 and 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2: Suppose you administer a questionnaire that involves the following question:\n",
    "\n",
    "- \"Do you strongly approve, somewhat approve, feel neutral about, somewhat disapprove, or strongly disapprove of the President's performance so far?\"\n",
    "\n",
    "You want to take these 1,000 survey responses as your $Y$ and build a model using geographic and demographic data to predict answers for the rest of your voting population. What generalized linear model is most appropriate here? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ordinal logistic regression. Because there are more than two discrete categories, but they are ordered in intensity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3: Suppose you administer a questionnaire that involves the following question:\n",
    "\n",
    "- \"When deciding who to vote for in the upcoming election, which of the following is most important? National security, jobs/economy, or social issues?\"\n",
    "\n",
    "You want to take these 1,000 survey responses as your $Y$ and build a model using geographic and demographic data to predict answers for the rest of your voting population. What generalized linear model is most appropriate here? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Multinomial logistic regression. Because there are  3 discrete, unordered categorical response values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4: Suppose you administer a questionnaire that involves the following question:\n",
    "\n",
    "- \"In the past week, how many times have you seen a commercial or advertisement involving this candidate?\"\n",
    "\n",
    "You want to take these 1,000 survey responses as your $Y$ and build a model using geographic and demographic data to predict answers for the rest of your voting population. What generalized linear model is most appropriate here? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Poisson regression. There are an inifnite number of discrete 'categories' and there is no reason to suspect\n",
    "#that variance is greater than the e(x). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5: In this problem, we'll guide you through (partially) using a new type of GLM. However, as you do this problem, think about this in the broader context of data science. In particular:\n",
    "- If you observe something weird in the data, can you explain why it's happening? Don't just think about data munging errors you might have made - also think about causes beyond your control, like data collection or measurement.\n",
    "- If you know your data are telling you something, can you model it?\n",
    "\n",
    "Suppose I have access to voting history and demographic information for all people in the state of Virginia. There's a column for whether or not people voted in the 2016 election.\n",
    "- Consider a 35 year old woman who did not vote in the 2016 election. She has a `0` in the `2016_voted` column.\n",
    "- Consider a 14 year old man who did not vote in the 2016 election. He has a `0` in the `2016_voted` column.\n",
    "\n",
    "In a Pandas DataFrame, the zeros look exactly the same. There's no difference in our DataFrame between a `0` because someone chose to not vote and a `0` because someone wasn't legally allowed to vote. Python won't know the difference, but you and I will! Because of this, we probably don't want to just pass these `0`s into `statsmodels` like they're all the same... instead, we might want to find a modeling technique that can account for this! *(If this doesn't make sense, chat with a classmate or your local instructor before moving on.)*\n",
    "\n",
    "There are special types of models called \"zero-inflated\" models that can handle exactly this situation - where there are more zeros than we'd expect, but some of the zeros are \"structural,\" or caused by some other process. (In this specific instance, we observe more zeros because of the age restriction on voting.) In cases where there are a lot of zeros, we might want to explore the data and the problem we're trying to solve to understand why there are so many zeros.\n",
    "- Our first question is: Are there more zeros than we'd expect?\n",
    "    - If yes, move to the second question.\n",
    "    - If no, we probably don't need to consider a zero-inflated model.\n",
    "- Our second question is: Is there some explanation for why we observe so many zeros? (i.e. data collection, data transcription error, measurement error...)\n",
    "    - If yes, then let's try to model that.\n",
    "    - If no, then proceed with caution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Summary**: The state wildlife biologists want to model how many fish are being caught by fishermen at a state park. Visitors are asked how long they stayed, how many people were in the group, were there children in the group and how many fish were caught. Some visitors do not fish, but there is no data on whether a person fished or not.\n",
    "\n",
    "We'll be using the fish data below. Your $Y$ variable is `count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fish = pd.read_csv(\"https://stats.idre.ucla.edu/stat/data/fish.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5.1: Given the scenario above, how might this data be susceptible to having an inflated number of zeros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "#People who caught 0 fish (but fished) will look just like people who caught 0 fish and did NOT fish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5.2: Do some EDA to explore whether or not there are an inflated number of zeros in `count`. Try a few things, including:\n",
    "- Histogram of `count`.\n",
    "- Finding the mean of `count`, then overlaying a Poisson distribution with that mean on the histogram of `count`. Does it visually look like a good fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish.head()\n",
    "len(fish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a162e0d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "fish['count'].loc[fish['count'] < 60].plot.hist(bins=15)\n",
    "plt.hist(np.random.poisson(2.46, 248), bins=7, alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "248"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fish = fish.loc[fish['count'] < 40]\n",
    "len(fish)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5.3: If we have a Poisson distribution with a fixed mean $\\lambda$, we can find the exact percentage of zeros we would expect to see. Using the Poisson pdf, calculate $P(count=k) = \\frac{\\lambda^ke^{-\\lambda}}{k!}$ for $k = 0$. This should tell you the exact percentage of zeros we expect to see, assuming that the data truly follow a $Poisson(\\lambda)$ distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.085434950967321233"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import poisson\n",
    "dist = poisson(2.46)\n",
    "dist.pmf(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5.4: It was annoying to have to use the actual Poisson pdf, right? Let's get the computer to do the work for us. Instead of getting the exact percentage of zeros we would expect to see, you can use Monte Carlo simulations to answer this. Randomly simulate 1,000 observations from a $Poisson(\\lambda)$ distribution and see what percentage are equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "for p in range(1000):\n",
    "    dist = list(np.random.poisson(2.46, 248))\n",
    "    x.append(dist.count(0)/248)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.084846774193548385"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5.5: Based on your answers in 5.2-5.4, is there enough evidence that `count` has too many zeros to be modeled with a non-zero-inflated Poisson distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5725806451612904"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fish.loc[fish['count'] == 0])/248"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#There are WAY too man zeros. We need to use zero inflated (57% in data vs. ~8% in poisson dist). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5.6: **Regardless of your answer to 5.5**, build two Poisson regression models (without zero-inflation) predicting `count`. You should:\n",
    "- Do some additional EDA on your independent variables.\n",
    "- Build the two models.\n",
    "- Interpret at least two coefficients.\n",
    "- Compare the two models using deviance. \n",
    "    - **NOTE: You can only compare the two models if they are nested!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/slevin886/anaconda2/envs/python3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>count</td>      <th>  No. Observations:  </th>  <td>   248</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   243</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Poisson</td>     <th>  Df Model:          </th>  <td>     4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>log</td>       <th>  Scale:             </th>    <td>1.0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -611.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Tue, 06 Feb 2018</td> <th>  Deviance:          </th> <td>  898.15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>14:20:22</td>     <th>  Pearson chi2:      </th> <td>1.77e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>6</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>   -2.6937</td> <td>    0.264</td> <td>  -10.188</td> <td> 0.000</td> <td>   -3.212</td> <td>   -2.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>livebait</th> <td>    1.5109</td> <td>    0.234</td> <td>    6.452</td> <td> 0.000</td> <td>    1.052</td> <td>    1.970</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>camper</th>   <td>    0.5415</td> <td>    0.093</td> <td>    5.806</td> <td> 0.000</td> <td>    0.359</td> <td>    0.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>persons</th>  <td>    0.8828</td> <td>    0.041</td> <td>   21.578</td> <td> 0.000</td> <td>    0.803</td> <td>    0.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>child</th>    <td>   -1.4564</td> <td>    0.082</td> <td>  -17.711</td> <td> 0.000</td> <td>   -1.618</td> <td>   -1.295</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  count   No. Observations:                  248\n",
       "Model:                            GLM   Df Residuals:                      243\n",
       "Model Family:                 Poisson   Df Model:                            4\n",
       "Link Function:                    log   Scale:                             1.0\n",
       "Method:                          IRLS   Log-Likelihood:                -611.18\n",
       "Date:                Tue, 06 Feb 2018   Deviance:                       898.15\n",
       "Time:                        14:20:22   Pearson chi2:                 1.77e+03\n",
       "No. Iterations:                     6                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -2.6937      0.264    -10.188      0.000      -3.212      -2.175\n",
       "livebait       1.5109      0.234      6.452      0.000       1.052       1.970\n",
       "camper         0.5415      0.093      5.806      0.000       0.359       0.724\n",
       "persons        0.8828      0.041     21.578      0.000       0.803       0.963\n",
       "child         -1.4564      0.082    -17.711      0.000      -1.618      -1.295\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_poi = fish[['count']]\n",
    "x_poi = fish[['livebait', 'camper', 'persons', 'child']]\n",
    "x_poi = sm.add_constant(x_poi)\n",
    "glm_poi = sm.GLM(y_poi,\n",
    "                 x_poi,\n",
    "                 family = sm.families.Poisson()).fit()\n",
    "glm_poi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "livebait :  4.5308122135181375\n",
      "camper :  1.718640833439073\n",
      "persons :  2.4176653282087495\n",
      "child :  0.23308517241128512\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "variables = ['livebait', 'camper', 'persons', 'child']\n",
    "for y, x in enumerate(list(glm_poi.params)[1:]):\n",
    "    coef = math.exp(x)\n",
    "    print(variables[y], ': ', coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using livebait was associated on average with 4.53 additional fish caught, holding other variables constant. \n",
    "#An additional 1 person in the group is associated on average with 2.4 additional fish caught, holding other variables constant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>count</td>      <th>  No. Observations:  </th>  <td>   248</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   244</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Poisson</td>     <th>  Df Model:          </th>  <td>     3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>log</td>       <th>  Scale:             </th>    <td>1.0</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -880.08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Tue, 06 Feb 2018</td> <th>  Deviance:          </th> <td>  1435.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>14:17:49</td>     <th>  Pearson chi2:      </th> <td>2.68e+03</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>6</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>   -0.5165</td> <td>    0.237</td> <td>   -2.179</td> <td> 0.029</td> <td>   -0.981</td> <td>   -0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>livebait</th> <td>    1.5300</td> <td>    0.233</td> <td>    6.555</td> <td> 0.000</td> <td>    1.073</td> <td>    1.988</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>camper</th>   <td>    0.6227</td> <td>    0.093</td> <td>    6.714</td> <td> 0.000</td> <td>    0.441</td> <td>    0.804</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>child</th>    <td>   -0.9877</td> <td>    0.081</td> <td>  -12.253</td> <td> 0.000</td> <td>   -1.146</td> <td>   -0.830</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:                  count   No. Observations:                  248\n",
       "Model:                            GLM   Df Residuals:                      244\n",
       "Model Family:                 Poisson   Df Model:                            3\n",
       "Link Function:                    log   Scale:                             1.0\n",
       "Method:                          IRLS   Log-Likelihood:                -880.08\n",
       "Date:                Tue, 06 Feb 2018   Deviance:                       1435.9\n",
       "Time:                        14:17:49   Pearson chi2:                 2.68e+03\n",
       "No. Iterations:                     6                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.5165      0.237     -2.179      0.029      -0.981      -0.052\n",
       "livebait       1.5300      0.233      6.555      0.000       1.073       1.988\n",
       "camper         0.6227      0.093      6.714      0.000       0.441       0.804\n",
       "child         -0.9877      0.081    -12.253      0.000      -1.146      -0.830\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping persons\n",
    "y_poi = fish[['count']]\n",
    "x_poi = fish[['livebait', 'camper', 'child']]\n",
    "x_poi = sm.add_constant(x_poi)\n",
    "glm_poi2 = sm.GLM(y_poi,\n",
    "                 x_poi,\n",
    "                 family = sm.families.Poisson()).fit()\n",
    "glm_poi2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in Deviance:  537.800554561\n",
      "p-value of test of difference:  0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "D_poi =  glm_poi2.deviance - glm_poi.deviance \n",
    "print('Difference in Deviance: ', D_poi)\n",
    "pval_poi = 1 - chi2.cdf(D_poi, 1)\n",
    "print('p-value of test of difference: ', pval_poi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reduced model is NOT better. We can reject that the reduced model is better at the 1% level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BONUS:** **Regardless of your answer to 5.5**, build a **zero-inflated** Poisson regression model without zero-inflation predicting `count`. Interpret your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
