{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing I Lab\n",
    "\n",
    "In this lab we will further explore Scikit-Learn's capabilities to process text. We will use the 20 Newsgroup dataset, which is provided by Scikit-Learn. You can learn more about this data [here](http://qwone.com/~jason/20Newsgroups/). We will be using four categories: baseball, computer graphics, science (medicine) and science (space).\n",
    "\n",
    "**Goal:** Your goal in this lab will be to use the text in these various news sources to predict the category of news source. You will build a logistic regression model in `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard Data Science Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Getting that SKLearn Dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = [\n",
    "    'rec.sport.baseball',\n",
    "    'comp.graphics',\n",
    "    'sci.med',\n",
    "    'sci.space',\n",
    "]\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data inspection\n",
    "\n",
    "We have downloaded a few newsgroup categories and removed headers, footers and quotes.\n",
    "\n",
    "Because this is an SKLearn dataset, it comes with pre-split train and test sets (note we were able to call 'train' and 'test' in subset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's inspect `data_train`.\n",
    "\n",
    "- What data type is `data_train`?\n",
    "- Is it structured like a list or dictionary?\n",
    "\n",
    "Inspect `data_train['data']`.\n",
    "- How many data points does it contain?\n",
    "- Describe the first data point.\n",
    "\n",
    "Similarly, you should inspect `data_train['target']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2368"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['data'][0]\n",
    "len(data_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, ..., 0, 2, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['data'][9]\n",
    "data_train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bag-of-Words Model\n",
    "\n",
    "A \"bag-of-words\" model is one that ignores the punctuation and order of words and treats them as some unordered list.\n",
    "\n",
    "Let's train a model using a simple CountVectorizer.\n",
    "\n",
    "1. Initialize a standard CountVectorizer and fit the training data.\n",
    "    - How big is the feature dictionary?\n",
    "    - Eliminate English stop words.\n",
    "    - Check the size of the feature dictionary. Is it smaller?\n",
    "2. Fit a Logistic Regression model.\n",
    "    - Given that there are more than two classes, [check the documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) and [see what model](http://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html) is, by default, fit when you have more than two categories. \n",
    "    - Do we have a major concern with unbalanced classes here?\n",
    "    - Transform the training data using the trained vectorizer. (You'll create `X_train` and `y_train` here.)\n",
    "    - Transform the test data using the trained vectorizer. **Be careful to use the trained vectorizer without re-fitting it.** (You'll create `X_test` and `y_test` here.)\n",
    "        - (This is similar to when you use `.fit()` and `.predict()` in models. You fit on the training data, then predict with the testing data; you don't re-fit the model on the testing data!)\n",
    "    - Fit your model!\n",
    "    - Evaluate the performance of your Logistic Regression model on the features extracted by the CountVectorizer.\n",
    "\n",
    "#### BONUS:\n",
    "- Try some modifications:\n",
    "    - restrict the max_features\n",
    "    - change max_df and min_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2358</th>\n",
       "      <th>2359</th>\n",
       "      <th>2360</th>\n",
       "      <th>2361</th>\n",
       "      <th>2362</th>\n",
       "      <th>2363</th>\n",
       "      <th>2364</th>\n",
       "      <th>2365</th>\n",
       "      <th>2366</th>\n",
       "      <th>2367</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The O's just lost to the Rangers a few minutes...</td>\n",
       "      <td>\\n\\n\\tAsk the practitioner whether he uses the...</td>\n",
       "      <td>\\n\\nSjogren's syndrome has been known to induc...</td>\n",
       "      <td>\\nHi Janet,\\n\\nSounds exactly like mine.  Same...</td>\n",
       "      <td>Me, too... RBI are a worthless stat. Of course...</td>\n",
       "      <td>someone wrote in expressing concern about gett...</td>\n",
       "      <td>I am currently looking for a 3D graphics libra...</td>\n",
       "      <td>BoSox 3     Royals 1\\n\\nWP: Clemens (1-0)\\nLP:...</td>\n",
       "      <td>\\n\\n\\n   Try graPHIGS from IBM... It is an exc...</td>\n",
       "      <td>\\n\\n\\nI recall that the issue is that fat on t...</td>\n",
       "      <td>...</td>\n",
       "      <td>Any more news on Steve's status since he lost ...</td>\n",
       "      <td>\\n\\n\\nGood thing i stuck in a couple of questi...</td>\n",
       "      <td>I had allergy shots for about four years start...</td>\n",
       "      <td>Forwarded from Neal Ausman, Galileo Mission Di...</td>\n",
       "      <td>\\nHey Valentine, I don't see Boston with any w...</td>\n",
       "      <td>\\nHi there\\nI'm suffering from Sarcoidosis at ...</td>\n",
       "      <td>There is a nice little tool in Lucid emacs. It...</td>\n",
       "      <td>I have the need for displaying 2 1/2 D surface...</td>\n",
       "      <td>Subject: options before back surgery for protr...</td>\n",
       "      <td>Does anyone know ifthe STS-56 email press kit ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 2368 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                0     \\\n",
       "0  The O's just lost to the Rangers a few minutes...   \n",
       "\n",
       "                                                1     \\\n",
       "0  \\n\\n\\tAsk the practitioner whether he uses the...   \n",
       "\n",
       "                                                2     \\\n",
       "0  \\n\\nSjogren's syndrome has been known to induc...   \n",
       "\n",
       "                                                3     \\\n",
       "0  \\nHi Janet,\\n\\nSounds exactly like mine.  Same...   \n",
       "\n",
       "                                                4     \\\n",
       "0  Me, too... RBI are a worthless stat. Of course...   \n",
       "\n",
       "                                                5     \\\n",
       "0  someone wrote in expressing concern about gett...   \n",
       "\n",
       "                                                6     \\\n",
       "0  I am currently looking for a 3D graphics libra...   \n",
       "\n",
       "                                                7     \\\n",
       "0  BoSox 3     Royals 1\\n\\nWP: Clemens (1-0)\\nLP:...   \n",
       "\n",
       "                                                8     \\\n",
       "0  \\n\\n\\n   Try graPHIGS from IBM... It is an exc...   \n",
       "\n",
       "                                                9     \\\n",
       "0  \\n\\n\\nI recall that the issue is that fat on t...   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "\n",
       "                                                2358  \\\n",
       "0  Any more news on Steve's status since he lost ...   \n",
       "\n",
       "                                                2359  \\\n",
       "0  \\n\\n\\nGood thing i stuck in a couple of questi...   \n",
       "\n",
       "                                                2360  \\\n",
       "0  I had allergy shots for about four years start...   \n",
       "\n",
       "                                                2361  \\\n",
       "0  Forwarded from Neal Ausman, Galileo Mission Di...   \n",
       "\n",
       "                                                2362  \\\n",
       "0  \\nHey Valentine, I don't see Boston with any w...   \n",
       "\n",
       "                                                2363  \\\n",
       "0  \\nHi there\\nI'm suffering from Sarcoidosis at ...   \n",
       "\n",
       "                                                2364  \\\n",
       "0  There is a nice little tool in Lucid emacs. It...   \n",
       "\n",
       "                                                2365  \\\n",
       "0  I have the need for displaying 2 1/2 D surface...   \n",
       "\n",
       "                                                2366  \\\n",
       "0  Subject: options before back surgery for protr...   \n",
       "\n",
       "                                                2367  \n",
       "0  Does anyone know ifthe STS-56 email press kit ...  \n",
       "\n",
       "[1 rows x 2368 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data_train['data']).T\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words='english')\n",
    "cvec.fit(df.iloc[0])\n",
    "cvecdata = cvec.transform(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#without stopwords (29314), with stopwords (29013)\n",
    "new_df = pd.DataFrame(cvecdata.todense(), columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97804054054054057"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "model = lr.fit(new_df, data_train['target'])\n",
    "model.score(new_df, data_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.97      0.98       584\n",
      "          1       0.92      1.00      0.96       597\n",
      "          2       1.00      0.97      0.98       594\n",
      "          3       1.00      0.97      0.99       593\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_train['target'],preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NOW STARTING WITH TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(data_test['data']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvecdata_test = cvec.transform(df_test.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df_2 = pd.DataFrame(cvecdata_test.todense(), columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_predictions = model.predict(new_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.86      0.86       389\n",
      "          1       0.79      0.94      0.86       397\n",
      "          2       0.89      0.78      0.83       396\n",
      "          3       0.83      0.78      0.80       394\n",
      "\n",
      "avg / total       0.84      0.84      0.84      1576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_test['target'], test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics most common words\n",
      "space    810.0\n",
      "edu      594.0\n",
      "data     422.0\n",
      "like     397.0\n",
      "don      363.0\n",
      "just     360.0\n",
      "time     352.0\n",
      "year     348.0\n",
      "nasa     347.0\n",
      "image    340.0\n",
      "dtype: float64\n",
      "rec.sport.baseball most common words\n",
      "like     74.0\n",
      "don      70.0\n",
      "use      67.0\n",
      "know     64.0\n",
      "just     53.0\n",
      "think    45.0\n",
      "time     39.0\n",
      "year     36.0\n",
      "does     35.0\n",
      "good     33.0\n",
      "dtype: float64\n",
      "sci.med most common words\n",
      "like      20.0\n",
      "time      19.0\n",
      "don       19.0\n",
      "just      13.0\n",
      "files     12.0\n",
      "year      10.0\n",
      "run        9.0\n",
      "people     9.0\n",
      "know       7.0\n",
      "good       7.0\n",
      "dtype: float64\n",
      "sci.space most common words\n",
      "space       16.0\n",
      "edu         16.0\n",
      "like         6.0\n",
      "use          5.0\n",
      "time         5.0\n",
      "don          5.0\n",
      "think        5.0\n",
      "computer     5.0\n",
      "know         4.0\n",
      "just         4.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Here's some code that might provide an interesting look at the data.\n",
    "\n",
    "common_words = []\n",
    "\n",
    "for i in range(4):\n",
    "    word_count = new_df[new_df_2==i].sum(axis=0)\n",
    "    \n",
    "    print(data_train['target_names'][i], \"most common words\")\n",
    "    \n",
    "    cw = word_count.sort_values(ascending = False).head(10)\n",
    "    \n",
    "    print(cw)\n",
    "    \n",
    "    common_words.extend(cw.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#new_df[new_df_2==1].sum(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Hashing and TF-IDF\n",
    "\n",
    "Let's see if Hashing or TF-IDF improves the accuracy.\n",
    "\n",
    "1. Initialize a HashingVectorizer and repeat with no restriction on the number of features.\n",
    "    - Does the score improve with respect to the CountVectorizer?\n",
    "2. Initialize a TF-IDF Vectorizer and repeat the analysis above\n",
    "    - Does the score improve with respect to the CountVectorizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_train['data']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HashingVectorizer(alternate_sign=True, analyzer='word', binary=False,\n",
       "         decode_error='strict', dtype=<class 'numpy.float64'>,\n",
       "         encoding='utf-8', input='content', lowercase=True,\n",
       "         n_features=1048576, ngram_range=(1, 1), non_negative=False,\n",
       "         norm='l2', preprocessor=None, stop_words='english',\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hvec = HashingVectorizer(stop_words='english')\n",
    "hvec.fit(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(hvec.transform(df.iloc[0]).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = lr.fit(df, data_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.96      0.96       584\n",
      "          1       0.91      0.99      0.95       597\n",
      "          2       1.00      0.96      0.98       594\n",
      "          3       0.99      0.95      0.97       593\n",
      "\n",
      "avg / total       0.97      0.96      0.96      2368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_train['target'], preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame(hvec.transform(df_test.iloc[0]).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_2 = model.predict(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.87      0.87       389\n",
      "          1       0.80      0.92      0.85       397\n",
      "          2       0.86      0.80      0.83       396\n",
      "          3       0.85      0.79      0.82       394\n",
      "\n",
      "avg / total       0.85      0.84      0.84      1576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_test['target'], preds_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_train['data']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tvec = TfidfVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvec.fit(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tvec.transform(df.iloc[0]).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "model = lr.fit(df, data_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_tvec = model.predict(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.97      0.97       584\n",
      "          1       0.92      1.00      0.96       597\n",
      "          2       1.00      0.97      0.98       594\n",
      "          3       1.00      0.96      0.98       593\n",
      "\n",
      "avg / total       0.98      0.97      0.97      2368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_train['target'], preds_tvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_2 = pd.DataFrame(tvec.transform(df_test.iloc[0]).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_test = model.predict(df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.90      0.90       389\n",
      "          1       0.85      0.93      0.89       397\n",
      "          2       0.91      0.87      0.89       396\n",
      "          3       0.89      0.83      0.86       394\n",
      "\n",
      "avg / total       0.89      0.88      0.88      1576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(data_test['target'], preds_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### BONUS\n",
    "- Build a model comparing `rec.sport.baseball` to `sci.med`. Evaluate the model.\n",
    "- Build a separate model comparing `sci.med` to `sci.space`. Evaluate the model.\n",
    "- Compare the two model evaluations. Is it easier for one model to differentiate the two sources than another model? Why is that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
